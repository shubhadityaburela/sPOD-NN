{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a219ecef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# sPOD-NN for 1D wildland fire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09eef3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../sPOD/lib/')\n",
    "sys.path.append('../DL-ROM/LIB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba80fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from wildfire1D_sup import wildfire1D_sup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78cc59",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data generation / sPOD of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 0  # 0 for temperature and 1 for supply mass fraction\n",
    "test_val = 558.49\n",
    "\n",
    "if variable == 0:\n",
    "    name = \"T\"\n",
    "else:\n",
    "    name = \"S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fd250",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "q = np.load(os.path.abspath(\".\") + '/wildfire_data/1D/' + 'SnapShotMatrix' + str(test_val) + '.npy')\n",
    "shifts_test= np.load(os.path.abspath(\".\") + '/wildfire_data/1D/' + 'Shifts' + str(test_val) + '.npy')\n",
    "\n",
    "df = wildfire1D_sup(q, shifts_test, param_test_val=test_val, var=variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06e6bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ############################# Run sPOD on the data ########################## (only once)\n",
    "# impath = \"./wildfire_data/1D/save_Wildfire/\" + name + \"/\"\n",
    "# import os\n",
    "# import pickle\n",
    "# os.makedirs(impath, exist_ok=True)\n",
    "\n",
    "# Q_frames, U_list, TA_list_training, TA_list_interp, spod_modes = df.run_sPOD(spod_iter=2000)\n",
    "\n",
    "# with open(impath + 'Q_frames.data', 'wb') as filehandle:\n",
    "#     pickle.dump(Q_frames, filehandle)\n",
    "# with open(impath + 'U_list.data', 'wb') as filehandle:\n",
    "#     pickle.dump(U_list, filehandle)\n",
    "# with open(impath + 'TA_list_training.data', 'wb') as filehandle:\n",
    "#     pickle.dump(TA_list_training, filehandle)\n",
    "# with open(impath + 'TA_list_interp.data', 'wb') as filehandle:\n",
    "#     pickle.dump(TA_list_interp, filehandle)\n",
    "# with open(impath + 'spod_modes.data', 'wb') as filehandle:\n",
    "#     pickle.dump(spod_modes, filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d0f7b",
   "metadata": {},
   "source": [
    "## Assemble the training data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "impath = \"./wildfire_data/1D/save_Wildfire/\" + name + \"/\"\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "with open(impath + 'Q_frames.data', 'rb') as filehandle:\n",
    "    Q_frames = pickle.load(filehandle) \n",
    "with open(impath + 'U_list.data', 'rb') as filehandle:\n",
    "    U_list = pickle.load(filehandle) \n",
    "with open(impath + 'TA_list_training.data', 'rb') as filehandle:\n",
    "    TA_list_training = pickle.load(filehandle) \n",
    "with open(impath + 'TA_list_interp.data', 'rb') as filehandle:\n",
    "    TA_list_interp = pickle.load(filehandle) \n",
    "with open(impath + 'spod_modes.data', 'rb') as filehandle:\n",
    "    spod_modes = pickle.load(filehandle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0368179",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA_TRAIN = np.concatenate(TA_list_training, axis=0)\n",
    "SHIFTS_TRAIN = [df.shifts_train[0], df.shifts_train[2]]\n",
    "PARAMS_TRAIN = df.params_train\n",
    "\n",
    "u, s, vt = np.linalg.svd(np.squeeze(df.q_train), full_matrices=False)\n",
    "\n",
    "U_POD_TRAIN = u[:, :sum(spod_modes) + df.NumFrames - 1]\n",
    "TA_POD_TRAIN = np.diag(s[:sum(spod_modes) + df.NumFrames - 1]) @ vt[:sum(spod_modes) + df.NumFrames - 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9b467",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07fe82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ###################################### Only for DoF study #######################################\n",
    "# # No need to be performed again \n",
    "# # The results are shown in the paper\n",
    "\n",
    "# from Helper import *\n",
    "\n",
    "# frame_wise_sPOD = [4, 2, 4]\n",
    "# Nmf = spod_modes\n",
    "# time_amplitudes_1 = TA_TRAIN[:Nmf[0], :]\n",
    "# time_amplitudes_2 = TA_TRAIN[Nmf[0]:Nmf[0] + Nmf[1], :]\n",
    "# time_amplitudes_3 = TA_TRAIN[Nmf[0] + Nmf[1]:, :]\n",
    "# frame_amplitudes_list_training = [\n",
    "#     time_amplitudes_1[:frame_wise_sPOD[0], :],\n",
    "#     time_amplitudes_2[:frame_wise_sPOD[1], :],\n",
    "#     time_amplitudes_3[:frame_wise_sPOD[2], :]\n",
    "# ]\n",
    "\n",
    "# TA_TRAIN = np.concatenate(frame_amplitudes_list_training, axis=0)\n",
    "# U_list = [\n",
    "#     U_list[0][:, :frame_wise_sPOD[0]], \n",
    "#     U_list[1][:, :frame_wise_sPOD[1]], \n",
    "#     U_list[2][:, :frame_wise_sPOD[2]]\n",
    "# ]\n",
    "# spod_modes = frame_wise_sPOD\n",
    "\n",
    "# frame_amplitudes_list_interp = []\n",
    "# for frame in range(3):\n",
    "#     Nmodes = spod_modes[frame]\n",
    "#     VT = frame_amplitudes_list_training[frame]\n",
    "#     amplitudes = [np.reshape(VT[n, :], [df.Nsamples_train, len(df.t)]).T for n in range(Nmodes)]\n",
    "#     frame_amplitudes_list_interp.append(amplitudes)\n",
    "\n",
    "# TA_list_interp = frame_amplitudes_list_interp\n",
    "# U_POD_TRAIN = U_POD_TRAIN[:, :sum(spod_modes)]\n",
    "# TA_POD_TRAIN = TA_POD_TRAIN[:sum(spod_modes), :]\n",
    "\n",
    "# ############################################\n",
    "# data_shape = [len(df.x), 1, 1, df.Nsamples_train*len(df.t)]\n",
    "# dx = df.x[1] - df.x[0]\n",
    "# L = [df.x[-1]]\n",
    "\n",
    "# q_train = [U_list[0] @ frame_amplitudes_list_training[0], \n",
    "#           U_list[1] @ frame_amplitudes_list_training[1], \n",
    "#           U_list[2] @ frame_amplitudes_list_training[2]]\n",
    "# trafos = [\n",
    "# transforms(data_shape, L, shifts=SHIFTS_TRAIN[0], dx=[dx],\n",
    "#                           use_scipy_transform=False,\n",
    "#                           interp_order=5),\n",
    "# transforms(data_shape, L, shifts=np.zeros_like(SHIFTS_TRAIN[0]), trafo_type=\"identity\",\n",
    "#                           dx=[dx],\n",
    "#                           use_scipy_transform=False, interp_order=5),\n",
    "# transforms(data_shape, L, shifts=SHIFTS_TRAIN[1], dx=[dx],\n",
    "#                           use_scipy_transform=False,\n",
    "#                           interp_order=5)\n",
    "# ]\n",
    "\n",
    "# NumFrames = 3\n",
    "# q_sPOD = 0\n",
    "# for frame in range(NumFrames):\n",
    "#     q_sPOD += trafos[frame].apply(q_train[frame])\n",
    "# ############################################\n",
    "# q_POD = U_POD_TRAIN @ TA_POD_TRAIN\n",
    "# ############################################\n",
    "# Q_original = df.q_train\n",
    "# ############################################\n",
    "\n",
    "# num1 = np.sqrt(np.mean(np.linalg.norm(Q_original - q_sPOD, 2, axis=1) ** 2))\n",
    "# den1 = np.sqrt(np.mean(np.linalg.norm(Q_original, 2, axis=1) ** 2))\n",
    "\n",
    "# num2 = np.sqrt(np.mean(np.linalg.norm(Q_original - q_POD, 2, axis=1) ** 2))\n",
    "# den2 = np.sqrt(np.mean(np.linalg.norm(Q_original, 2, axis=1) ** 2))\n",
    "\n",
    "# print(\"Relative reconstruction error indicator for full snapshot(sPOD) is {}\".format(num1 / den1))\n",
    "# print(\"Relative reconstruction error indicator for full snapshot(POD) is {}\".format(num2 / den2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd267424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from Helper import save_fig\n",
    "\n",
    "# impath = \"../plots/images_wildfire1D/\"\n",
    "# os.makedirs(impath, exist_ok=True) \n",
    "\n",
    "# plt.rcParams.update({\n",
    "#     \"text.usetex\": True,\n",
    "#     \"font.family\": \"serif\",\n",
    "#     \"font.serif\": [\"Computer Modern\"]})\n",
    "\n",
    "# SMALL_SIZE = 16   # 16\n",
    "# MEDIUM_SIZE = 18   # 18\n",
    "# BIGGER_SIZE = 20   # 20\n",
    "\n",
    "# plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "# plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "# plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "# plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "# plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "# plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "# plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "\n",
    "# [Xgrid, Tgrid] = meshgrid(df.x, df.t)\n",
    "# Xgrid = Xgrid.T\n",
    "# Tgrid = Tgrid.T\n",
    "\n",
    "# Nt = len(df.t)\n",
    "# cmap = 'YlOrRd'\n",
    "\n",
    "# qmin = np.min(df.q_train[:, :Nt])\n",
    "# qmax = np.max(df.q_train[:, :Nt])\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(9, 5))\n",
    "# # Reconstruction\n",
    "# axs[0].pcolormesh(Xgrid, Tgrid, df.q_train[:, :Nt], vmin=qmin, vmax=qmax, cmap=cmap)\n",
    "# # axs[0].axis('off')\n",
    "# axs[0].axis('scaled')\n",
    "# axs[0].set_title(r\"$Q$\")\n",
    "# axs[0].set_yticks([], [])\n",
    "# axs[0].set_xticks([], [])\n",
    "# # 1. frame\n",
    "# axs[1].pcolormesh(Xgrid, Tgrid, q_POD[:, :Nt], vmin=qmin, vmax=qmax, cmap=cmap)\n",
    "# # axs[1].axis('off')\n",
    "# axs[1].axis('scaled')\n",
    "# axs[1].set_title(r\"$Q^{POD}$\")\n",
    "# axs[1].set_yticks([], [])\n",
    "# axs[1].set_xticks([], [])\n",
    "# # 2. frame\n",
    "# axs[2].pcolormesh(Xgrid, Tgrid, q_sPOD[:, :Nt], vmin=qmin, vmax=qmax, cmap=cmap)\n",
    "# # axs[2].axis('off')\n",
    "# axs[2].axis('scaled')\n",
    "# axs[2].set_title(r\"$Q^{sPOD}$\")\n",
    "# axs[2].set_yticks([], [])\n",
    "# axs[2].set_xticks([], [])\n",
    "\n",
    "# fig.supylabel(r\"time $t$\")\n",
    "# fig.supxlabel(r\"space $x$\")\n",
    "\n",
    "# save_fig(filepath=impath + \"PODvsPOD\", figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48445d",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441509b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Assemble the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51c960",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################# Run sPOD on the test data ########################## (only once)\n",
    "import os\n",
    "impath = \"./wildfire_data/1D/save_Wildfire/\" + name + \"/\" + str(test_val) + \"/\"\n",
    "import pickle\n",
    "os.makedirs(impath, exist_ok=True)\n",
    "\n",
    "Q_frames_test = df.test_data(spod_iter=2000)\n",
    "\n",
    "with open(impath + 'Q_frames_test.data', 'wb') as filehandle:\n",
    "    pickle.dump(Q_frames_test, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d452638",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "impath = \"./wildfire_data/1D/save_Wildfire/\" + name + \"/\" + str(test_val) + \"/\"\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "with open(impath + 'Q_frames_test.data', 'rb') as filehandle:\n",
    "    Q_frames_test = pickle.load(filehandle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f27a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the sPOD decomposed frames for test parameter\n",
    "# df.plot_sPOD_frames(Q_frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78700011",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_vecs_test = np.asarray([df.param_test_val])\n",
    "params_test = [np.squeeze(np.asarray([[np.ones_like(df.t) * mu], [df.t]])) for mu in mu_vecs_test]\n",
    "PARAMS_TEST = np.concatenate(params_test, axis=1)\n",
    "\n",
    "q1_test = Q_frames_test[0]\n",
    "q2_test = Q_frames_test[1]\n",
    "q3_test = Q_frames_test[2]\n",
    "\n",
    "time_amplitudes_1_test = U_list[0].transpose() @ q1_test\n",
    "time_amplitudes_2_test = U_list[1].transpose() @ q2_test\n",
    "time_amplitudes_3_test = U_list[2].transpose() @ q3_test\n",
    "TA_TEST = np.concatenate((time_amplitudes_1_test, \n",
    "                          time_amplitudes_2_test, \n",
    "                          time_amplitudes_3_test), axis=0)\n",
    "\n",
    "SHIFTS_TEST = [df.shifts_test[0], df.shifts_test[2]]\n",
    "\n",
    "TA_POD_TEST = U_POD_TRAIN.transpose() @ df.q_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccbe869",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca22da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Grid, Nx : {}, Nt : {}\".format(len(df.x), len(df.t)))\n",
    "print(\"Number of sPOD frames : {}\".format(len(spod_modes)))\n",
    "print(\"Number of modes (frame wise) : {}, {}, {}\".format(spod_modes[0], spod_modes[1], spod_modes[2]))\n",
    "print(\"Size of training matrix : {} x {}\".format(int(TA_TRAIN.shape[0]), int(TA_TRAIN.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ae8ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for any data manipulations that need to be done for the network input\n",
    "\n",
    "# \"0\" shift has not been included in the prediction \n",
    "shifts_train = np.concatenate((np.reshape(SHIFTS_TRAIN[0], newshape=[1, -1]), np.reshape(SHIFTS_TRAIN[1], newshape=[1, -1])), axis=0)\n",
    "shifts_test = np.concatenate((np.reshape(SHIFTS_TEST[0], newshape=[1, -1]), np.reshape(SHIFTS_TEST[1], newshape=[1, -1])), axis=0)\n",
    "\n",
    "ta_train = np.concatenate((TA_TRAIN, shifts_train), axis=0)\n",
    "ta_test = np.concatenate((TA_TEST, shifts_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a70c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Network prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf9ffa3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_sPOD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': len(df.x),  # N_h\n",
    "        'reduced_order_model_dimension': ta_train.shape[0],  # N\n",
    "        'totalModes': ta_train.shape[0] - len(spod_modes) + 1,  # Total number of modes for all the frames\n",
    "        'num_early_stop': 3000  # Early stop criteria \n",
    "    }\n",
    "params_POD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': len(df.x),  # N_h\n",
    "        'reduced_order_model_dimension': TA_POD_TRAIN.shape[0],  # N\n",
    "        'totalModes': TA_POD_TRAIN.shape[0],  # Total number of modes for all the frames\n",
    "        'num_early_stop': 3000  # Early stop criteria \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2aa490",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # training the model\n",
    "# from DFNN import run_model \n",
    "# import time\n",
    "# tic_sPOD = time.process_time() \n",
    "# print(\"#################################\")\n",
    "# print(\"sPOD-NN\")\n",
    "# model_sPOD, _, scaling_sPOD = run_model(ta_train, PARAMS_TRAIN, epochs=100000, lr=0.005, loss_type='L1', \n",
    "#                                         logs_folder='./DNN_result/wildfire1D/training_results_sPOD/' + name, \n",
    "#                                         params=params_sPOD, batch_size=100)\n",
    "# print(\"#################################\\n\")\n",
    "# toc_sPOD = time.process_time()\n",
    "\n",
    "# tic_POD = time.process_time()\n",
    "# print(\"#################################\")\n",
    "# print(\"POD-NN\")\n",
    "# model_POD, _, scaling_POD = run_model(TA_POD_TRAIN, PARAMS_TRAIN, epochs=100000, lr=0.005, loss_type='L1', \n",
    "#                                       logs_folder='./DNN_result/wildfire1D/training_results_POD/' + name, \n",
    "#                                       params=params_POD, batch_size=100)\n",
    "# print(\"#################################\\n\")\n",
    "# toc_POD = time.process_time()\n",
    "\n",
    "# print(f\"Time consumption in training (sPOD-NN) : {toc_sPOD - tic_sPOD:0.4f} seconds\")\n",
    "# print(f\"Time consumption in training (POD-NN) : {toc_POD - tic_POD:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db16f5",
   "metadata": {},
   "source": [
    "## Network testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to do a query test \"query\" or full test \"full\"\n",
    "test = {\n",
    "    'typeOfTest': \"full\",\n",
    "    'test_sample': 400\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62f6bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import os\n",
    "from DFNN import scale_params\n",
    "\n",
    "# Load the correct model\n",
    "log_folder_base_sPOD = 'DNN_result/wildfire1D/training_results_sPOD/' + name + '/'\n",
    "log_folder_trained_model_sPOD = sorted(pathlib.Path(log_folder_base_sPOD).glob('*/'), key=os.path.getmtime)[-1]\n",
    "PATH_sPOD = str(log_folder_trained_model_sPOD) + '/trained_weights/' + 'weights.pt'\n",
    "\n",
    "log_folder_base_POD = 'DNN_result/wildfire1D/training_results_POD/' + name + '/'\n",
    "log_folder_trained_model_POD = sorted(pathlib.Path(log_folder_base_POD).glob('*/'), key=os.path.getmtime)[-1]\n",
    "PATH_POD = str(log_folder_trained_model_POD) + '/trained_weights/' + 'weights.pt'\n",
    "\n",
    "PATH_sPOD = 'DNN_result/wildfire1D/training_results_sPOD/' + name + '/2023_02_07__14-07-57/trained_weights/weights.pt'\n",
    "PATH_POD = 'DNN_result/wildfire1D/training_results_POD/' + name + '/2023_02_07__14-16-32/trained_weights/weights.pt'\n",
    "\n",
    "# Scale the parameters before prediction\n",
    "if '/trained_weights/weights.pt' in PATH_sPOD: address_sPOD = PATH_sPOD.replace('/trained_weights/weights.pt', '')\n",
    "scaling_sPOD = np.load(address_sPOD + '/variables/' + 'scaling.npy', allow_pickle=True)\n",
    "\n",
    "if '/trained_weights/weights.pt' in PATH_POD: address_POD = PATH_POD.replace('/trained_weights/weights.pt', '')\n",
    "scaling_POD = np.load(address_POD + '/variables/' + 'scaling.npy', allow_pickle=True)\n",
    "\n",
    "PARAMS_TEST_sPOD = scale_params(PARAMS_TEST, params_sPOD, scaling_sPOD)\n",
    "PARAMS_TEST_POD = scale_params(PARAMS_TEST, params_POD, scaling_POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef868d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test['typeOfTest'] == \"query\":\n",
    "    test_sample = test['test_sample']\n",
    "    \n",
    "    ta_test = ta_test[:, test_sample][..., np.newaxis]\n",
    "    \n",
    "    TA_TEST = TA_TEST[:, test_sample][..., np.newaxis]\n",
    "    TA_POD_TEST = TA_POD_TEST[:, test_sample][..., np.newaxis]\n",
    "    \n",
    "    tmp = []\n",
    "    for i in range(df.NumFrames):\n",
    "        tt = []\n",
    "        for m in range(spod_modes[i]):\n",
    "            ampl = TA_list_interp[i][m][test_sample, :][np.newaxis, ...]\n",
    "            tt.append(ampl)\n",
    "        tmp.append(tt)\n",
    "    TA_list_interp = tmp\n",
    "    \n",
    "    SHIFTS_TEST[0] = SHIFTS_TEST[0][test_sample]\n",
    "    SHIFTS_TEST[1] = SHIFTS_TEST[1][test_sample]\n",
    "    \n",
    "    PARAMS_TEST_sPOD = PARAMS_TEST_sPOD[:, test_sample][..., np.newaxis]\n",
    "    PARAMS_TEST_POD = PARAMS_TEST_POD[:, test_sample][..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a18b64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing the model\n",
    "from DFNN import test_model \n",
    "import time \n",
    "\n",
    "tic = time.process_time()\n",
    "rel_err_sPOD, results_predicted_sPOD = test_model(ta_test, PARAMS_TEST_sPOD, trained_model=None, saved_model=True, \n",
    "                                                  PATH_TO_WEIGHTS=PATH_sPOD, params=params_sPOD, scaling=scaling_sPOD, \n",
    "                                                  batch_size=100) \n",
    "toc = time.process_time()\n",
    "print(f\"Time consumption in testing sPOD-NN model : {toc - tic:0.4f} seconds\")\n",
    "\n",
    "tic = time.process_time()\n",
    "rel_err_POD, results_predicted_POD = test_model(TA_POD_TEST, PARAMS_TEST_POD, trained_model=None, saved_model=True, \n",
    "                                                PATH_TO_WEIGHTS=PATH_POD, params=params_POD, scaling=scaling_POD, \n",
    "                                                batch_size=100)\n",
    "toc = time.process_time()\n",
    "print(f\"Time consumption in testing POD-NN model : {toc - tic:0.4f} seconds\")\n",
    "\n",
    "\n",
    "print(rel_err_sPOD, rel_err_POD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f9d7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Online prediction analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e89978",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for data manipulations for the online analysis\n",
    "frame_amplitudes_predicted_sPOD = results_predicted_sPOD[:-2, :]\n",
    "shifts_predicted_sPOD = results_predicted_sPOD[-2:, :]\n",
    "frame_amplitudes_predicted_POD = results_predicted_POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204744d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "errors = df.plot_online_data(frame_amplitudes_predicted_sPOD, frame_amplitudes_predicted_POD, TA_TEST, \n",
    "                             TA_POD_TEST, TA_list_interp, shifts_predicted_sPOD, SHIFTS_TEST, spod_modes, \n",
    "                             U_list, U_POD_TRAIN, Q_frames_test, plot_online=False, test_type=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ef821",
   "metadata": {},
   "source": [
    "## Error Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231008d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from Helper import save_fig\n",
    "from statistics import mean\n",
    "\n",
    "impath = \"../plots/images_wildfire1D/\"\n",
    "os.makedirs(impath, exist_ok=True) \n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Computer Modern\"]})\n",
    "\n",
    "SMALL_SIZE = 16   # 16\n",
    "MEDIUM_SIZE = 18   # 18\n",
    "BIGGER_SIZE = 20   # 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd4f11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Error plot for temperature\n",
    "truncated_modes = np.array([3, 6, 10, 14, 20, 24, 36, 42])\n",
    "E_sPOD_NN = np.array([0.39350, 0.23411, 0.15384, 0.10032, 0.07252, 0.04094, 0.03998, 0.03789])\n",
    "E_sPOD_I = np.array([0.23652, 0.23153, 0.07831, 0.04052, 0.03835, 0.03673, 0.03648, 0.03646])\n",
    "E_POD_NN = np.array([0.69294, 0.50367, 0.35548, 0.26727, 0.18598, 0.14853, 0.08672, 0.07854])\n",
    "\n",
    "err = errors[0]\n",
    "err_max = np.amax(err, axis=0)\n",
    "err_min = np.amin(err, axis=0)\n",
    "err_mean = np.mean(err, axis=0)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axs[0].semilogy(truncated_modes, E_sPOD_NN, color=\"red\", linestyle='--', marker=\"*\", label=r\"$E^{\\mathrm{sPOD-NN}}_{\\mathrm{tot}}$\")\n",
    "axs[0].semilogy(truncated_modes, E_sPOD_I, color=\"blue\", linestyle='--', marker=\"*\", label=r\"$E^{\\mathrm{sPOD-I}}_{\\mathrm{tot}}$\")\n",
    "axs[0].semilogy(truncated_modes, E_POD_NN, color=\"black\", linestyle='--', marker=\"*\", label=r\"$E^{\\mathrm{POD-NN}}_{\\mathrm{tot}}$\")\n",
    "axs[0].set_xlabel('Number of modes')\n",
    "axs[0].set_ylabel('Errors')\n",
    "axs[0].grid()\n",
    "axs[0].legend(loc='upper right')\n",
    "\n",
    "axs[1].semilogy(df.t, err_max, color=\"teal\", linestyle='--', label=r\"max$(E^{\\mathrm{sPOD-NN}}_{\\mathrm{t}})$\")\n",
    "axs[1].semilogy(df.t, err_mean, color=\"orange\", linestyle='--', label=r\"mean$(E^{\\mathrm{sPOD-NN}}_{\\mathrm{t}})$\")\n",
    "axs[1].semilogy(df.t, err_min, color=\"dimgrey\", linestyle='--', label=r\"min$(E^{\\mathrm{sPOD-NN}}_{\\mathrm{t}})$\")\n",
    "axs[1].set_xlabel(r\"time $t$\")\n",
    "axs[1].grid()\n",
    "axs[1].legend(loc='lower right')\n",
    "\n",
    "\n",
    "save_fig(filepath=impath + 'Rel_err', figure=fig)\n",
    "fig.savefig(impath + \"Rel_err\" + \".eps\", format='eps',dpi=600, transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
