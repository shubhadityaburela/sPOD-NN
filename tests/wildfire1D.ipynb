{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a219ecef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Neural network prediction for the sPOD-DL-ROM for WIldfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09eef3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../DL/')\n",
    "sys.path.append('../sPOD/lib/')\n",
    "sys.path.append('../DL-ROM/LIB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba80fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from wildfire1D import wildfire1D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78cc59",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data generation / Shifted POD of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fd250",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = wildfire1D(spod_iter=5, var=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec7768",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "impath = \"./wildfire_data/save_Wildfire/\"\n",
    "import os\n",
    "import pickle\n",
    "os.makedirs(impath, exist_ok=True)\n",
    "\n",
    "np.save(impath + 'TA_TRAIN.npy', df.TA_TRAIN)\n",
    "np.save(impath + 'SHIFTS_TRAIN.npy', df.SHIFTS_TRAIN)\n",
    "np.save(impath + 'PARAMS_TRAIN.npy', df.PARAMS_TRAIN)\n",
    "np.save(impath + 'U_POD_TRAIN.npy', df.U_POD_TRAIN)\n",
    "np.save(impath + 'TA_POD_TRAIN.npy', df.TA_POD_TRAIN)\n",
    "with open(impath + 'U_list.data', 'wb') as filehandle:\n",
    "    pickle.dump(df.U_list, filehandle)\n",
    "with open(impath + 'spodModes.data', 'wb') as filehandle:\n",
    "    pickle.dump(df.spodModes, filehandle)\n",
    "with open(impath + 'frame_amplitude_list.data', 'wb') as filehandle:\n",
    "    pickle.dump(df.frame_amplitude_list, filehandle)\n",
    "with open(impath + 'shifts_list.data', 'wb') as filehandle:\n",
    "    pickle.dump(df.shifts_list, filehandle)\n",
    "np.save(impath + 'x.npy', df.x)\n",
    "np.save(impath + 't.npy', df.t)\n",
    "np.save(impath + 'MU_VECS_TRAIN.npy', df.mu_vecs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ca7ca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the data for NN predictions and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388581ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c70c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "impath = \"./wildfire_data/save_Wildfire/\"\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "TA_TRAIN = np.load(impath + 'TA_TRAIN.npy')\n",
    "SHIFTS_TRAIN = np.load(impath + 'SHIFTS_TRAIN.npy')\n",
    "PARAMS_TRAIN = np.load(impath + 'PARAMS_TRAIN.npy')\n",
    "U_POD_TRAIN = np.load(impath + 'U_POD_TRAIN.npy')\n",
    "TA_POD_TRAIN = np.load(impath + 'TA_POD_TRAIN.npy')\n",
    "with open(impath + 'U_list.data', 'rb') as filehandle:\n",
    "    U_list = pickle.load(filehandle) \n",
    "with open(impath + 'spodModes.data', 'rb') as filehandle:\n",
    "    spodModes = pickle.load(filehandle) \n",
    "with open(impath + 'frame_amplitude_list.data', 'rb') as filehandle:\n",
    "    frame_amplitude_list = pickle.load(filehandle) \n",
    "with open(impath + 'shifts_list.data', 'rb') as filehandle:\n",
    "    shifts_list = pickle.load(filehandle) \n",
    "x = np.load(impath + 'x.npy')\n",
    "t = np.load(impath + 't.npy')\n",
    "MU_VECS_TRAIN = np.load(impath + 'MU_VECS_TRAIN.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07fe82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Temporary cell for dof study.\n",
    "\n",
    "frame_wise_sPOD = [15, 20, 15]\n",
    "Nmf = spodModes\n",
    "time_amplitudes_1 = TA_TRAIN[:Nmf[0], :]\n",
    "time_amplitudes_2 = TA_TRAIN[Nmf[0]:Nmf[0] + Nmf[1], :]\n",
    "time_amplitudes_3 = TA_TRAIN[Nmf[0] + Nmf[1]:, :]\n",
    "\n",
    "frame_amplitudes_training = [\n",
    "    time_amplitudes_1[:frame_wise_sPOD[0], :],\n",
    "    time_amplitudes_2[:frame_wise_sPOD[1], :],\n",
    "    time_amplitudes_3[:frame_wise_sPOD[2], :]\n",
    "]\n",
    "TA_TRAIN = np.concatenate(frame_amplitudes_training, axis=0)\n",
    "U_list = [\n",
    "    U_list[0][:, :frame_wise_sPOD[0]], \n",
    "    U_list[1][:, :frame_wise_sPOD[1]], \n",
    "    U_list[2][:, :frame_wise_sPOD[2]]\n",
    "]\n",
    "spodModes = frame_wise_sPOD\n",
    "\n",
    "frame_amplitude_list = []\n",
    "Nsamples_train = 3\n",
    "for frame in range(3):\n",
    "    Nmodes = spodModes[frame]\n",
    "    VT = frame_amplitudes_training[frame]\n",
    "    amplitudes = [np.reshape(VT[n, :], [Nsamples_train, len(t)]).T for n in range(Nmodes)]\n",
    "    frame_amplitude_list.append(amplitudes)\n",
    "\n",
    "    \n",
    "    \n",
    "frame_wise_POD = sum(frame_wise_sPOD) + 2\n",
    "U_POD_TRAIN = U_POD_TRAIN[:, :frame_wise_POD]\n",
    "TA_POD_TRAIN = TA_POD_TRAIN[:frame_wise_POD, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8388c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from Helper import *\n",
    "############################################\n",
    "data_shape = [len(x), 1, 1, 3*len(t)]\n",
    "dx = x[1] - x[0]\n",
    "L = [x[-1]]\n",
    "\n",
    "q_train = [U_list[0] @ frame_amplitudes_training[0], \n",
    "          U_list[1] @ frame_amplitudes_training[1], \n",
    "          U_list[2] @ frame_amplitudes_training[2]]\n",
    "trafos = [\n",
    "transforms(data_shape, L + dx, shifts=SHIFTS_TRAIN[0], dx=[dx],\n",
    "                          use_scipy_transform=False,\n",
    "                          interp_order=5),\n",
    "transforms(data_shape, L + dx, shifts=np.zeros_like(SHIFTS_TRAIN[0]), trafo_type=\"identity\",\n",
    "                          dx=[dx],\n",
    "                          use_scipy_transform=False, interp_order=5),\n",
    "transforms(data_shape, L + dx, shifts=SHIFTS_TRAIN[1], dx=[dx],\n",
    "                          use_scipy_transform=False,\n",
    "                          interp_order=5)\n",
    "]\n",
    "\n",
    "NumFrames = 3\n",
    "q_sPOD = 0\n",
    "for frame in range(NumFrames):\n",
    "    q_sPOD += trafos[frame].apply(q_train[frame])\n",
    "\n",
    "############################################\n",
    "q_POD = U_POD_TRAIN @ TA_POD_TRAIN\n",
    "############################################\n",
    "import os\n",
    "dat1_train = np.load(os.path.abspath(\".\") + '/wildfire_data/' + 'SnapShotMatrix540.npy')\n",
    "dat2_train = np.load(os.path.abspath(\".\") + '/wildfire_data/' + 'SnapShotMatrix560.npy')\n",
    "dat3_train = np.load(os.path.abspath(\".\") + '/wildfire_data/' + 'SnapShotMatrix580.npy')\n",
    "q_train_total = np.concatenate((dat1_train, dat2_train, dat3_train), axis=1)\n",
    "Q_original = q_train_total[0:len(x), :]\n",
    "############################################\n",
    "\n",
    "num1 = np.sqrt(np.mean(np.linalg.norm(Q_original - q_sPOD, 2, axis=1) ** 2))\n",
    "den1 = np.sqrt(np.mean(np.linalg.norm(Q_original, 2, axis=1) ** 2))\n",
    "\n",
    "num2 = np.sqrt(np.mean(np.linalg.norm(Q_original - q_POD, 2, axis=1) ** 2))\n",
    "den2 = np.sqrt(np.mean(np.linalg.norm(Q_original, 2, axis=1) ** 2))\n",
    "\n",
    "print(num1/den1)\n",
    "print(num2/den2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441509b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51c960",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from wildfire1D import wildfire1D_testing\n",
    "\n",
    "Q = np.load(os.path.abspath(\".\") + '/wildfire_data/' + 'SnapShotMatrix558_49.npy')\n",
    "delta = np.load(os.path.abspath(\".\") + '/wildfire_data/' + 'Shifts558_49.npy')\n",
    "\n",
    "\n",
    "###########################################\n",
    "Q = Q[:, :len(t)]\n",
    "delta = delta[:, :len(t)]\n",
    "###########################################\n",
    "\n",
    "TA_TEST, TA_POD_TEST, SHIFTS_TEST, PARAMS_TEST, MU_VECS_TEST, q_test, q1_test, q2_test, q3_test = wildfire1D_testing(Q, delta, U_list, U_POD_TRAIN, x, t, val=558.49, var=0, spod_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3007b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "impath = \"./wildfire_data/save_Wildfire/\"\n",
    "import os\n",
    "import pickle\n",
    "os.makedirs(impath, exist_ok=True)\n",
    "\n",
    "np.save(impath + 'TA_TEST.npy', TA_TEST)\n",
    "np.save(impath + 'TA_POD_TEST.npy', TA_POD_TEST)\n",
    "np.save(impath + 'SHIFTS_TEST.npy', SHIFTS_TEST)\n",
    "np.save(impath + 'PARAMS_TEST.npy', PARAMS_TEST)\n",
    "np.save(impath + 'MU_VECS_TEST.npy', MU_VECS_TEST)\n",
    "np.save(impath + 'q_test.npy', q_test)\n",
    "np.save(impath + 'q1_test.npy', q1_test)\n",
    "np.save(impath + 'q2_test.npy', q2_test)\n",
    "np.save(impath + 'q3_test.npy', q3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d452638",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "impath = \"./wildfire_data/save_Wildfire/\"\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "TA_TEST = np.load(impath + 'TA_TEST.npy')\n",
    "TA_POD_TEST = np.load(impath + 'TA_POD_TEST.npy')\n",
    "SHIFTS_TEST = np.load(impath + 'SHIFTS_TEST.npy')\n",
    "PARAMS_TEST = np.load(impath + 'PARAMS_TEST.npy')\n",
    "MU_VECS_TEST = np.load(impath + 'MU_VECS_TEST.npy')\n",
    "q_test = np.load(impath + 'q_test.npy')\n",
    "q1_test = np.load(impath + 'q1_test.npy')\n",
    "q2_test = np.load(impath + 'q2_test.npy')\n",
    "q3_test = np.load(impath + 'q3_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3f1b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Temporary cell for time study\n",
    "time_amplitudes_1_test = U_list[0].transpose() @ q1_test\n",
    "time_amplitudes_2_test = U_list[1].transpose() @ q2_test\n",
    "time_amplitudes_3_test = U_list[2].transpose() @ q3_test\n",
    "amplitudes_test = np.concatenate(\n",
    "    (time_amplitudes_1_test, time_amplitudes_2_test, time_amplitudes_3_test), axis=0)\n",
    "\n",
    "TA_TEST = amplitudes_test\n",
    "\n",
    "TA_POD_TEST = U_POD_TRAIN.transpose() @ q_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d1022b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2e19a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from Helper import *\n",
    "\n",
    "U, S, VT = randomized_svd(q_test, n_components=6)\n",
    "q_POD = U @ (np.diag(S) @ VT)\n",
    "\n",
    "\n",
    "############################################\n",
    "data_shape = [len(x), 1, 1, len(t)]\n",
    "dx = x[1] - x[0]\n",
    "L = [x[-1]]\n",
    "\n",
    "q_pred = [q1_test, q2_test, q3_test]\n",
    "trafos = [\n",
    "transforms(data_shape, L + dx, shifts=SHIFTS_TEST[0], dx=[dx],\n",
    "                          use_scipy_transform=False,\n",
    "                          interp_order=5),\n",
    "transforms(data_shape, L + dx, shifts=np.zeros_like(SHIFTS_TEST[0]), trafo_type=\"identity\",\n",
    "                          dx=[dx],\n",
    "                          use_scipy_transform=False, interp_order=5),\n",
    "transforms(data_shape, L + dx, shifts=SHIFTS_TEST[1], dx=[dx],\n",
    "                          use_scipy_transform=False,\n",
    "                          interp_order=5)\n",
    "]\n",
    "\n",
    "NumFrames = 3\n",
    "q_sPOD = 0\n",
    "for frame in range(NumFrames):\n",
    "    q_sPOD += trafos[frame].apply(q_pred[frame])\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "[X_grid, t_grid] = np.meshgrid(x, t)\n",
    "X_grid = X_grid.T\n",
    "t_grid = t_grid.T\n",
    "impath = \"../plots/images_wildfire1D/\"\n",
    "os.makedirs(impath, exist_ok=True)\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "vmin = np.min(q_test)\n",
    "vmax = np.max(q_test)\n",
    "# Original\n",
    "axs[0].pcolormesh(X_grid, t_grid, q_test, vmin=vmin, vmax=vmax)\n",
    "axs[0].set_ylabel(r\"$t$\")\n",
    "axs[0].set_yticks([], [])\n",
    "axs[0].set_xlabel(r'$x$')\n",
    "axs[0].set_xticks([], [])\n",
    "axs[0].set_title(r\"$Q$\")\n",
    "# POD\n",
    "axs[1].pcolormesh(X_grid, t_grid, q_POD, vmin=vmin, vmax=vmax)\n",
    "axs[1].set_yticks([], [])\n",
    "axs[1].set_xlabel(r'$x$')\n",
    "axs[1].set_xticks([], [])\n",
    "axs[1].set_title(r\"$Q^\" + \"{POD}$\")\n",
    "# sPOD\n",
    "axs[2].pcolormesh(X_grid, t_grid, q_sPOD, vmin=vmin, vmax=vmax)\n",
    "axs[2].set_xlabel(r'$x$')\n",
    "axs[2].set_yticks([], [])\n",
    "axs[2].set_xticks([], [])\n",
    "axs[2].set_title(r\"$Q^\" + \"{sPOD}$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_fig(filepath=impath + \"PODvsPOD\", figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b73cc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from Helper import *\n",
    "impath = \"../plots/images_wildfire1D/\"\n",
    "\n",
    "truncated_modes = np.array([0, 1, 3, 6, 15, 20, 35, 50, 64])\n",
    "recon_err_POD = np.array([1, 0.86462, 0.55, 0.38, 0.22, 0.16, 0.07, 0.038, 0.021])\n",
    "recon_err_sPOD = np.array([1, 0.86462, 0.41, 0.41, 0.025, 0.024, 0.0015, 0.00025, 0.0000528])\n",
    "fig = plt.figure()\n",
    "plt.semilogy(truncated_modes, recon_err_POD, color=\"red\", marker=\".\", label='POD')\n",
    "plt.semilogy(truncated_modes, recon_err_sPOD, color=\"blue\", marker=\".\", label='sPOD')\n",
    "plt.xlabel('Number of modes', fontsize=14)\n",
    "plt.ylabel('Relative reconstruction error', fontsize=14)\n",
    "plt.title('Modes vs error', fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend(loc='center right')\n",
    "save_fig(filepath=impath + 'MvE', figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed267d66",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "impath = \"./wildfire_data/save_Wildfire/\"\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from Helper import *\n",
    "\n",
    "Q = np.load(os.path.abspath(\".\") + '/wildfire_data/' + 'SnapShotMatrix558_49.npy')\n",
    "\n",
    "[X_grid, t_grid] = np.meshgrid(x, t)\n",
    "X_grid = X_grid.T\n",
    "t_grid = t_grid.T\n",
    "impath = \"../plots/images_wildfire1D/\"\n",
    "os.makedirs(impath, exist_ok=True)\n",
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "# Original\n",
    "axs[0].pcolormesh(X_grid, t_grid, Q[:len(x), :])\n",
    "# axs[0].set_ylabel(r\"$t$\")\n",
    "axs[0].set_yticks([], [])\n",
    "# axs[0].set_xlabel(r'$x$')\n",
    "axs[0].set_xticks([], [])\n",
    "axs[0].set_title(r\"$T$\")\n",
    "# POD\n",
    "axs[1].pcolormesh(X_grid, t_grid, Q[len(x):, :])\n",
    "axs[1].set_yticks([], [])\n",
    "# axs[1].set_xlabel(r'$x$')\n",
    "axs[1].set_xticks([], [])\n",
    "axs[1].set_title(r\"$S$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "save_fig(filepath=impath + \"TvS\", figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7bb03a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca22da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Grid, Nx : {}, Nt : {}\".format(len(x), len(t)))\n",
    "print(\"Number of sPOD frames : {}\".format(len(spodModes)))\n",
    "print(\"Number of modes (frame wise) : {}, {}, {}\".format(spodModes[0], spodModes[1], spodModes[2]))\n",
    "print(\"Size of training matrix : {} x {}\".format(int(TA_TRAIN.shape[0]), int(TA_TRAIN.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ae8ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for any data manipulations that need to be done for the network input\n",
    "\n",
    "# \"0\" shift has not been included in the prediction \n",
    "shifts_train = np.concatenate((np.reshape(SHIFTS_TRAIN[0], newshape=[1, -1]), np.reshape(SHIFTS_TRAIN[1], newshape=[1, -1])), axis=0)\n",
    "shifts_test = np.concatenate((np.reshape(SHIFTS_TEST[0], newshape=[1, -1]), np.reshape(SHIFTS_TEST[1], newshape=[1, -1])), axis=0)\n",
    "\n",
    "ta_train = np.concatenate((TA_TRAIN, shifts_train), axis=0)\n",
    "ta_test = np.concatenate((TA_TEST, shifts_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367c544",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a70c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c191c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Path for the pretrained weights\n",
    "PATH_sPOD = 'DNN_result/wildfire1D/training_results_sPOD/T/2022_08_29__11-29-59/trained_weights/weights.pt'\n",
    "PATH_POD = 'DNN_result/wildfire1D/training_results_POD/T/2022_08_29__12-14-13/trained_weights/weights.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf9ffa3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_sPOD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': len(x),  # N_h\n",
    "        'reduced_order_model_dimension': ta_train.shape[0],  # N\n",
    "        'totalModes': ta_train.shape[0] - len(spodModes) - 1,  # Total number of modes for all the frames\n",
    "    }\n",
    "params_POD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': len(x),  # N_h\n",
    "        'reduced_order_model_dimension': TA_POD_TRAIN.shape[0],  # N\n",
    "        'totalModes': TA_POD_TRAIN.shape[0],  # Total number of modes for all the frames\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2aa490",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "from network import run_model \n",
    "print(\"#################################\")\n",
    "print(\"sPOD-DL-ROM\")\n",
    "model_sPOD, scaling_sPOD = run_model(ta_train, PARAMS_TRAIN, epochs=100, lr=0.05, loss='L1', \n",
    "                       logs_folder='./DNN_result/wildfire1D/training_results_sPOD/T',\n",
    "                      pretrained_load=False, pretrained_weights=PATH_sPOD, params=params_sPOD)\n",
    "print(\"#################################\\n\")\n",
    "print(\"#################################\")\n",
    "print(\"POD-DL-ROM\")\n",
    "model_POD, scaling_POD = run_model(TA_POD_TRAIN, PARAMS_TRAIN, epochs=100, lr=0.05, loss='L1', \n",
    "                      logs_folder='./DNN_result/wildfire1D/training_results_POD/T',\n",
    "                     pretrained_load=False, pretrained_weights=PATH_POD, params=params_POD)\n",
    "print(\"#################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62f6bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loading the model\n",
    "import torch\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "log_folder_base_sPOD = 'DNN_result/wildfire1D/training_results_sPOD/T/'\n",
    "log_folder_trained_model_sPOD = sorted(pathlib.Path(log_folder_base_sPOD).glob('*/'), key=os.path.getmtime)[-1]\n",
    "PATH_sPOD = str(log_folder_trained_model_sPOD) + '/trained_weights/' + 'weights.pt'\n",
    "\n",
    "\n",
    "log_folder_base_POD = 'DNN_result/wildfire1D/training_results_POD/T/'\n",
    "log_folder_trained_model_POD = sorted(pathlib.Path(log_folder_base_POD).glob('*/'), key=os.path.getmtime)[-1]\n",
    "PATH_POD = str(log_folder_trained_model_POD) + '/trained_weights/' + 'weights.pt'\n",
    "\n",
    "\n",
    "# PATH_sPOD = 'DNN/Wildfire/training_results_local_sPOD/T/2022_09_01__22-55-10/trained_weights/weights.pt'\n",
    "# PATH_POD = 'DNN/Wildfire/training_results_local_POD/T/2022_09_02__00-03-56/trained_weights/weights.pt'\n",
    "\n",
    "print(PATH_sPOD)\n",
    "print(PATH_POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302dc7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from network import scale_params\n",
    "\n",
    "if '/trained_weights/weights.pt' in PATH_sPOD: address_sPOD = PATH_sPOD.replace('/trained_weights/weights.pt', '')\n",
    "scaling_sPOD = np.load(address_sPOD + '/variables/' + 'scaling.npy', allow_pickle=True)\n",
    "\n",
    "if '/trained_weights/weights.pt' in PATH_POD: address_POD = PATH_POD.replace('/trained_weights/weights.pt', '')\n",
    "scaling_POD = np.load(address_POD + '/variables/' + 'scaling.npy', allow_pickle=True)\n",
    "\n",
    "PARAMS_TEST_sPOD = scale_params(PARAMS_TEST, params_sPOD, scaling_sPOD)\n",
    "PARAMS_TEST_POD = scale_params(PARAMS_TEST, params_POD, scaling_POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2871e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(ta_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a18b64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing the model\n",
    "from network import test_model \n",
    "import time \n",
    "\n",
    "tic = time.process_time()\n",
    "rel_err_sPOD, results_predicted_sPOD = test_model(ta_test, PARAMS_TEST_sPOD, \n",
    "                                                  trained_model=None, saved_model=True,\n",
    "                                                 PATH_TO_WEIGHTS=PATH_sPOD, params=params_sPOD, \n",
    "                                                  scaling=scaling_sPOD) \n",
    "toc = time.process_time()\n",
    "print(f\"Time consumption in testing sPOD DL model : {toc - tic:0.4f} seconds\")\n",
    "\n",
    "tic = time.process_time()\n",
    "rel_err_POD, results_predicted_POD = test_model(TA_POD_TEST, PARAMS_TEST_POD, \n",
    "                                                trained_model=None, saved_model=True,\n",
    "                                               PATH_TO_WEIGHTS=PATH_POD, params=params_POD,\n",
    "                                               scaling=scaling_POD)\n",
    "toc = time.process_time()\n",
    "print(f\"Time consumption in testing POD DL model : {toc - tic:0.4f} seconds\")\n",
    "\n",
    "\n",
    "print(rel_err_sPOD, rel_err_POD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13ffdf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gradient boosted regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff6dc2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_sPOD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': len(x),  # N_h\n",
    "        'reduced_order_model_dimension': ta_train.shape[0],  # N\n",
    "        'totalModes': ta_train.shape[0] - len(spodModes) - 1,  # Total number of modes for all the frames\n",
    "    }\n",
    "params_POD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': len(x),  # N_h\n",
    "        'reduced_order_model_dimension': TA_POD_TRAIN.shape[0],  # N\n",
    "        'totalModes': TA_POD_TRAIN.shape[0],  # Total number of modes for all the frames\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0472929",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "from GBRT import run_model \n",
    "print(\"#################################\")\n",
    "print(\"sPOD-DL-ROM\")\n",
    "model_sPOD_list, scaling_sPOD = run_model(ta_train, PARAMS_TRAIN, params_sPOD)\n",
    "print(\"#################################\\n\")\n",
    "print(\"#################################\")\n",
    "print(\"POD-DL-ROM\")\n",
    "model_POD_list, scaling_POD = run_model(TA_POD_TRAIN, PARAMS_TRAIN, params_POD)\n",
    "print(\"#################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf775d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path = \"./GBRT/Wildfire/64new/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "with open(path + 'sPOD.pkl', 'wb') as f:\n",
    "    pickle.dump(model_sPOD_list, f)\n",
    "    \n",
    "with open(path + 'POD.pkl', 'wb') as f:\n",
    "    pickle.dump(model_POD_list, f)\n",
    "    \n",
    "with open(path + 'scaling_sPOD.pkl', 'wb') as f:\n",
    "    pickle.dump(scaling_sPOD, f)\n",
    "    \n",
    "with open(path + 'scaling_POD.pkl', 'wb') as f:\n",
    "    pickle.dump(scaling_POD, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d05297",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "path = \"./GBRT/Wildfire/64new/\"\n",
    "\n",
    "model_sPOD_list = joblib.load(path + 'sPOD.pkl')\n",
    "model_POD_list = joblib.load(path + 'POD.pkl')\n",
    "scaling_sPOD = joblib.load(path + 'scaling_sPOD.pkl')\n",
    "scaling_POD = joblib.load(path + 'scaling_POD.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045ea22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from GBRT import scale_params\n",
    "PARAMS_TEST_sPOD = scale_params(PARAMS_TEST, scaling_sPOD)\n",
    "PARAMS_TEST_POD = scale_params(PARAMS_TEST, scaling_POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c55b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# testing the model\n",
    "from GBRT import test_model \n",
    "import time \n",
    "\n",
    "print(\"#################################\")\n",
    "tic = time.process_time()\n",
    "results_predicted_sPOD = test_model(ta_test, PARAMS_TEST_sPOD, \n",
    "                                                  trained_model_list=model_sPOD_list,\n",
    "                                                  scaling=scaling_sPOD, params=params_sPOD) \n",
    "toc = time.process_time()\n",
    "print(f\"Time consumption in testing sPOD DL model : {toc - tic:0.4f} seconds\")\n",
    "print(\"#################################\\n\")\n",
    "print(\"#################################\")\n",
    "tic = time.process_time()\n",
    "results_predicted_POD = test_model(TA_POD_TEST, PARAMS_TEST_POD, \n",
    "                                                trained_model_list=model_POD_list,\n",
    "                                                scaling=scaling_POD, params=params_POD)\n",
    "toc = time.process_time()\n",
    "print(f\"Time consumption in testing POD DL model : {toc - tic:0.4f} seconds\")\n",
    "print(\"#################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aad3df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convolutional autoencoder and DNN coupled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4e03f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from TrainingFramework import TrainingFramework\n",
    "from TestingFramework import TestingFramework\n",
    "import Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca553ba3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_network_sPOD = {\n",
    "        'time_amplitude_train': ta_train,\n",
    "        'time_amplitude_test': ta_test,\n",
    "        'parameter_train': PARAMS_TRAIN,\n",
    "        'parameter_test': PARAMS_TEST,\n",
    "        'batch_size': 500,\n",
    "        'num_early_stop': 2000,  # Number of epochs for the early stopping\n",
    "        'pretrained_load': False,  # Wthere to initialize the network with pretrained weights\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'perform_svd': 'randomized',  # 'normal', 'randomized'\n",
    "        'learning_rate': 0.1,  # eta\n",
    "        'full_order_model_dimension': len(x),  # N_h\n",
    "        'reduced_order_model_dimension': ta_train.shape[0],  # N\n",
    "        'encoded_dimension': 4,  # dimension of the system after the encoder\n",
    "        'omega_h': 0.5,\n",
    "        'omega_N': 0.5,\n",
    "        'typeConv': '1D',  # Type of convolutional layer for the network : '1D' or '2D'\n",
    "        'totalModes': ta_train.shape[0] - len(spodModes) - 1,  # Total number of modes for all the frames\n",
    "    }\n",
    "\n",
    "\n",
    "dict_network_POD = {\n",
    "        'time_amplitude_train': TA_POD_TRAIN,\n",
    "        'time_amplitude_test': TA_POD_TEST,\n",
    "        'parameter_train': PARAMS_TRAIN,\n",
    "        'parameter_test': PARAMS_TEST,\n",
    "        'batch_size': 500,\n",
    "        'num_early_stop': 2000,  # Number of epochs for the early stopping\n",
    "        'pretrained_load': False,  # Wthere to initialize the network with pretrained weights\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'perform_svd': 'randomized',  # 'normal', 'randomized'\n",
    "        'learning_rate': 0.1,  # eta\n",
    "        'full_order_model_dimension': len(x),  # N_h\n",
    "        'reduced_order_model_dimension': TA_POD_TRAIN.shape[0],  # N\n",
    "        'encoded_dimension': 4,  # dimension of the system after the encoder\n",
    "        'omega_h': 0.5,\n",
    "        'omega_N': 0.5,\n",
    "        'typeConv': '1D',  # Type of convolutional layer for the network : '1D' or '2D'\n",
    "        'totalModes': TA_POD_TRAIN.shape[0],  # Total number of modes for all the frames\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245ea8c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9438cb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select the path to the pre trained weights\n",
    "PATH_sPOD = 'CADNN_result/synthetic/training_results_sPOD/2022_08_23__19-55-17/net_weights/epoch_99.pt'\n",
    "PATH_POD = 'CADNN_result/synthetic/training_results_POD/2022_08_23__19-55-17/net_weights/epoch_99.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a5672",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training model for sPOD\n",
    "train_model_sPOD = TrainingFramework(dict_network_sPOD, split=0.70, \n",
    "                                     log_folder='./CADNN_result/wildfire1D/training_results_sPOD/T/')\n",
    "trained_model_sPOD = train_model_sPOD.training(epochs=100, save_every=50, print_every=50, \n",
    "                                               log_base_name='/', pretrained_weights=PATH_sPOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32819a73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Testing model for sPOD\n",
    "testing_method = ''\n",
    "\n",
    "log_folder_base = 'CADNN_result/wildfire1D/training_results_sPOD/T/'\n",
    "log_folder_trained_model = sorted(pathlib.Path(log_folder_base).glob('*/'), key=os.path.getmtime)[-1]\n",
    "\n",
    "test_model_sPOD = TestingFramework(dict_network_sPOD)\n",
    "test_model_sPOD.testing(log_folder_trained_model=str(log_folder_trained_model), \n",
    "                        testing_method=testing_method, model=trained_model_sPOD)\n",
    "results_predicted_sPOD = test_model_sPOD.time_amplitude_test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3d617e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd6fc9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training model for POD\n",
    "train_model_POD = TrainingFramework(dict_network_POD, split=0.70, \n",
    "                                    log_folder='./CADNN_result/wildfire1D/training_results_POD/T/')\n",
    "trained_model_POD = train_model_POD.training(epochs=100, save_every=50, print_every=50, \n",
    "                                             log_base_name='/', pretrained_weights=PATH_POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7cc8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Testing model for POD\n",
    "testing_method = ''\n",
    "\n",
    "log_folder_base = 'CADNN_result/wildfire1D/training_results_POD/T/'\n",
    "log_folder_trained_model = sorted(pathlib.Path(log_folder_base).glob('*/'), key=os.path.getmtime)[-1]\n",
    "\n",
    "test_model_POD = TestingFramework(dict_network_POD)\n",
    "test_model_POD.testing(log_folder_trained_model=str(log_folder_trained_model), \n",
    "                       testing_method=testing_method, model=trained_model_POD)\n",
    "results_predicted_POD = test_model_POD.time_amplitude_test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cbf2f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f9d7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Online error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e89978",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for data manipulations for the online analysis\n",
    "frame_amplitudes_predicted_sPOD = results_predicted_sPOD[:-2, :]\n",
    "shifts_predicted_sPOD = results_predicted_sPOD[-2:, :]\n",
    "frame_amplitudes_predicted_POD = results_predicted_POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204744d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wildfire1D import onlineErroranalysis\n",
    "tmp = onlineErroranalysis(frame_amplitudes_predicted_sPOD, \n",
    "                    TA_TEST,\n",
    "                    TA_POD_TEST,\n",
    "                    frame_amplitude_list,\n",
    "                    shifts_predicted_sPOD,\n",
    "                    SHIFTS_TEST,\n",
    "                    shifts_list,\n",
    "                    frame_amplitudes_predicted_POD,\n",
    "                    spodModes,\n",
    "                    U_list,\n",
    "                    U_POD_TRAIN,\n",
    "                    q_test,\n",
    "                    q1_test,\n",
    "                    q2_test,\n",
    "                    q3_test,\n",
    "                    MU_VECS_TRAIN,\n",
    "                    MU_VECS_TEST,\n",
    "                    x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95853842",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from Helper import *\n",
    "impath = \"../plots/images_wildfire1D/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182bdd1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "truncated_modes = np.array([3, 6, 15, 20, 35, 50, 64])\n",
    "recon_err_POD = np.array([0.55695, 0.38588, 0.221744, 0.167523, 0.09577, 0.10325, 0.08427])\n",
    "recon_err_sPOD = np.array([0.99486, 0.96774, 0.18548, 0.18436, 0.06719, 0.0554, 0.03354])\n",
    "recon_err_interp = np.array([0.27787, 0.2768, 0.05805, 0.05771, 0.05576, 0.05573, 0.05573])\n",
    "fig = plt.figure()\n",
    "plt.semilogy(truncated_modes, recon_err_POD, color=\"green\", linestyle='-', marker=\".\", label='POD')\n",
    "plt.semilogy(truncated_modes, recon_err_sPOD, color=\"red\", linestyle='--', marker=\"+\", label='sPOD')\n",
    "plt.semilogy(truncated_modes, recon_err_interp, color=\"blue\", linestyle='--', marker=\"*\", label='Interpolated')\n",
    "plt.xlabel('Number of modes', fontsize=14)\n",
    "plt.ylabel('rel. error', fontsize=14)\n",
    "plt.title('Modes vs error', fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "save_fig(filepath=impath + 'MvE_online', figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18002c12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "truncated_modes = np.array([545, 550, 555, 558.49, 565, 570, 575])\n",
    "recon_err_POD = np.array([0.55695, 0.38588, 0.221744, 0.167523, 0.09577, 0.10325, 0.08427])\n",
    "recon_err_sPOD = np.array([0.99486, 0.96774, 0.18548, 0.18436, 0.06719, 0.0554, 0.03354])\n",
    "recon_err_interp = np.array([0.27787, 0.2768, 0.05805, 0.05771, 0.05576, 0.05573, 0.05573])\n",
    "fig = plt.figure()\n",
    "plt.semilogy(truncated_modes, recon_err_POD, color=\"green\", linestyle='-', marker=\".\", label='POD')\n",
    "plt.semilogy(truncated_modes, recon_err_sPOD, color=\"red\", linestyle='--', marker=\"+\", label='sPOD')\n",
    "plt.semilogy(truncated_modes, recon_err_interp, color=\"blue\", linestyle='--', marker=\"*\", label='Interpolated')\n",
    "plt.xlabel(r'$\\beta$', fontsize=14)\n",
    "plt.ylabel('rel. error', fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "save_fig(filepath=impath + 'betavE', figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ee358",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
