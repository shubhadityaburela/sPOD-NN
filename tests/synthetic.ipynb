{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a219ecef",
   "metadata": {},
   "source": [
    "# Neural network prediction for the sPOD-DL-ROM for Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../DL/')\n",
    "sys.path.append('../sPOD/lib/')\n",
    "sys.path.append('../DL-ROM/LIB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic import synthetic\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78cc59",
   "metadata": {},
   "source": [
    "## Data generation / Shifted POD of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fd250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = synthetic(spod_iter=300)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313ef62",
   "metadata": {},
   "source": [
    "## Input data for the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889026db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We collect the time amplitudes, shifts and the parameters for the training as well as the testing data.\n",
    "TA_TRAIN = df.TA_TRAIN\n",
    "SHIFTS_TRAIN = df.SHIFTS_TRAIN\n",
    "PARAMS_TRAIN = df.PARAMS_TRAIN\n",
    "TA_TEST = df.TA_TEST\n",
    "SHIFTS_TEST = df.SHIFTS_TEST\n",
    "PARAMS_TEST = df.PARAMS_TEST\n",
    "TA_POD_TRAIN = df.TA_POD_TRAIN\n",
    "TA_POD_TEST = df.TA_POD_TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67733f",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b60b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dof study\n",
    "frame_wise_sPOD = [8, 8]\n",
    "time_amplitudes_1 = TA_TRAIN[:df.nmodes, :]\n",
    "time_amplitudes_2 = TA_TRAIN[df.nmodes:, :]\n",
    "\n",
    "frame_amplitudes_training = [\n",
    "    time_amplitudes_1[:frame_wise_sPOD[0], :],\n",
    "    time_amplitudes_2[:frame_wise_sPOD[1], :]\n",
    "]\n",
    "\n",
    "TA_TRAIN = np.concatenate(frame_amplitudes_training, axis=0)\n",
    "U_list = [\n",
    "    df.U_list[0][:, :frame_wise_sPOD[0]], \n",
    "    df.U_list[1][:, :frame_wise_sPOD[1]]\n",
    "]\n",
    "spodModes = frame_wise_sPOD\n",
    "\n",
    "    \n",
    "frame_wise_POD = sum(frame_wise_sPOD) + 2\n",
    "U_POD_TRAIN = df.U_POD_TRAIN[:, :frame_wise_POD]\n",
    "TA_POD_TRAIN = df.TA_POD_TRAIN[:frame_wise_POD, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from Helper import *\n",
    "############################################\n",
    "data_shape = [len(df.x), 1, 1, 4*len(df.t)]\n",
    "dx = df.x[1] - df.x[0]\n",
    "L = [df.x[-1]]\n",
    "\n",
    "q_train = [U_list[0] @ frame_amplitudes_training[0], \n",
    "          U_list[1] @ frame_amplitudes_training[1]]\n",
    "\n",
    "trafos = df.trafos_train\n",
    "\n",
    "NumFrames = 2\n",
    "q_sPOD = 0\n",
    "for frame in range(NumFrames):\n",
    "    q_sPOD += trafos[frame].apply(q_train[frame])\n",
    "############################################\n",
    "q_POD = U_POD_TRAIN @ TA_POD_TRAIN\n",
    "############################################\n",
    "q_original = df.q_train[0:len(df.x), :]\n",
    "############################################\n",
    "\n",
    "num1 = np.sqrt(np.mean(np.linalg.norm(q_original - q_sPOD, 2, axis=1) ** 2))\n",
    "den1 = np.sqrt(np.mean(np.linalg.norm(q_original, 2, axis=1) ** 2))\n",
    "\n",
    "num2 = np.sqrt(np.mean(np.linalg.norm(q_original - q_POD, 2, axis=1) ** 2))\n",
    "den2 = np.sqrt(np.mean(np.linalg.norm(q_original, 2, axis=1) ** 2))\n",
    "\n",
    "print(\"Error for sPOD recons. is {}\".format(num1 / den1))\n",
    "print(\"Error for POD recons. is {}\".format(num2 / den2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc8bd4c",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid, Nx : {}, Nt : {}\".format(df.Nx, df.Nt))\n",
    "print(\"Number of sPOD frames : {}\".format(df.NumFrames))\n",
    "print(\"Number of modes per frame : {}\".format(df.nmodes))\n",
    "print(\"Number of parameter instances : {}\".format(int(int(TA_TRAIN.shape[1]) / df.Nt)))\n",
    "print(\"Size of training matrix : {} x {}\".format(int(TA_TRAIN.shape[0]), int(TA_TRAIN.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ae8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is reserved for any data manipulations that need to be done for the network input\n",
    "shifts_train = np.concatenate((np.reshape(SHIFTS_TRAIN[0], newshape=[1, -1]), np.reshape(SHIFTS_TRAIN[1], newshape=[1, -1])), axis=0)\n",
    "shifts_test = np.concatenate((np.reshape(SHIFTS_TEST[0], newshape=[1, -1]), np.reshape(SHIFTS_TEST[1], newshape=[1, -1])), axis=0)\n",
    "\n",
    "ta_train = np.concatenate((TA_TRAIN, shifts_train), axis=0)\n",
    "ta_test = np.concatenate((TA_TEST, shifts_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c1bb0",
   "metadata": {},
   "source": [
    "## Feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the pretrained weights\n",
    "PATH_sPOD = 'DNN_result/syntheticOnlyTA/training_results_sPOD/2022_08_25__12-34-47/trained_weights/weights.pt'\n",
    "PATH_POD = 'DNN_result/synthetic/training_results_sPOD/2022_08_23__18-56-21/trained_weights/weights.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sPOD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': df.Nx,  # N_h\n",
    "        'reduced_order_model_dimension': df.D * df.NumFrames + df.NumFrames,  # N\n",
    "        'totalModes': df.D * df.NumFrames,  # Total number of modes for all the frames\n",
    "        'num_early_stop': 1000  # early stop criteria \n",
    "    \n",
    "    }\n",
    "params_POD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': df.Nx,  # N_h\n",
    "        'reduced_order_model_dimension': df.D * df.NumFrames + df.NumFrames,  # N\n",
    "        'totalModes': df.D * df.NumFrames + df.NumFrames,  # Total number of modes for all the frames\n",
    "        'num_early_stop': 1000  # early stop criteria \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2aa490",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "from network import run_model \n",
    "print(\"#################################\")\n",
    "print(\"sPOD-DL-ROM\")\n",
    "trained_model_sPOD, scaling_sPOD = run_model(ta_train, PARAMS_TRAIN, epochs=1000, lr=0.01, loss_type='L1', \n",
    "                       logs_folder='./DNN_result/synthetic/training_results_sPOD',\n",
    "                      pretrained_load=False, pretrained_weights=PATH_sPOD, params=params_sPOD, batch_size=100)\n",
    "print(\"#################################\\n\")\n",
    "print(\"#################################\")\n",
    "print(\"POD-DL-ROM\")\n",
    "trained_model_POD, scaling_POD = run_model(TA_POD_TRAIN, PARAMS_TRAIN, epochs=1000, lr=0.01, loss_type='L1', \n",
    "                      logs_folder='./DNN_result/synthetic/training_results_POD',\n",
    "                     pretrained_load=False, pretrained_weights=PATH_POD, params=params_POD, batch_size=100)\n",
    "print(\"#################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "import torch\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "log_folder_base_sPOD = 'DNN_result/synthetic/training_results_sPOD/'\n",
    "log_folder_trained_model_sPOD = sorted(pathlib.Path(log_folder_base_sPOD).glob('*/'), key=os.path.getmtime)[-1]\n",
    "PATH_sPOD = str(log_folder_trained_model_sPOD) + '/trained_weights/' + 'weights.pt'\n",
    "\n",
    "\n",
    "log_folder_base_POD = 'DNN_result/synthetic/training_results_POD/'\n",
    "log_folder_trained_model_POD = sorted(pathlib.Path(log_folder_base_POD).glob('*/'), key=os.path.getmtime)[-1]\n",
    "PATH_POD = str(log_folder_trained_model_POD) + '/trained_weights/' + 'weights.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import scale_params\n",
    "PARAMS_TEST_sPOD = scale_params(PARAMS_TEST, params_sPOD, scaling_sPOD)\n",
    "PARAMS_TEST_POD = scale_params(PARAMS_TEST, params_POD, scaling_POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2399d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model\n",
    "from network import test_model \n",
    "rel_err_sPOD, results_predicted_sPOD = test_model(ta_test, PARAMS_TEST_sPOD, \n",
    "                                                  saved_model=True, \n",
    "                                                  PATH_TO_WEIGHTS=PATH_sPOD, params=params_sPOD,\n",
    "                                                  scaling=scaling_sPOD, batch_size=100) \n",
    "rel_err_POD, results_predicted_POD = test_model(TA_POD_TEST, PARAMS_TEST_POD, \n",
    "                                                saved_model=True,\n",
    "                                               PATH_TO_WEIGHTS=PATH_POD, params=params_POD,\n",
    "                                               scaling=scaling_POD, batch_size=100)\n",
    "print(rel_err_sPOD, rel_err_POD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7702c",
   "metadata": {},
   "source": [
    "## Gradient boosted regression trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sPOD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': len(df.x),  # N_h\n",
    "        'reduced_order_model_dimension': ta_train.shape[0],  # N\n",
    "        'totalModes': df.nmodes * df.NumFrames,  # Total number of modes for all the frames\n",
    "    }\n",
    "params_POD = {\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'full_order_model_dimension': len(df.x),  # N_h\n",
    "        'reduced_order_model_dimension': TA_POD_TRAIN.shape[0],  # N\n",
    "        'totalModes': TA_POD_TRAIN.shape[0],  # Total number of modes for all the frames\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ecf5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "from GBRT import run_model \n",
    "print(\"#################################\")\n",
    "print(\"sPOD-DL-ROM\")\n",
    "model_sPOD_list, scaling_sPOD = run_model(ta_train, PARAMS_TRAIN, params_sPOD)\n",
    "print(\"#################################\\n\")\n",
    "print(\"#################################\")\n",
    "print(\"POD-DL-ROM\")\n",
    "model_POD_list, scaling_POD = run_model(TA_POD_TRAIN, PARAMS_TRAIN, params_POD)\n",
    "print(\"#################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efbaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GBRT import scale_params\n",
    "PARAMS_TEST_sPOD = scale_params(PARAMS_TEST, scaling_sPOD)\n",
    "PARAMS_TEST_POD = scale_params(PARAMS_TEST, scaling_POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2bbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model\n",
    "from GBRT import test_model \n",
    "import time \n",
    "\n",
    "print(\"#################################\")\n",
    "tic = time.process_time()\n",
    "results_predicted_sPOD = test_model(ta_test, PARAMS_TEST_sPOD, \n",
    "                                                  trained_model_list=model_sPOD_list,\n",
    "                                                  scaling=scaling_sPOD, params=params_sPOD) \n",
    "toc = time.process_time()\n",
    "print(f\"Time consumption in testing sPOD DL model : {toc - tic:0.4f} seconds\")\n",
    "print(\"#################################\\n\")\n",
    "print(\"#################################\")\n",
    "tic = time.process_time()\n",
    "results_predicted_POD = test_model(TA_POD_TEST, PARAMS_TEST_POD, \n",
    "                                                trained_model_list=model_POD_list,\n",
    "                                                scaling=scaling_POD, params=params_POD)\n",
    "toc = time.process_time()\n",
    "print(f\"Time consumption in testing POD DL model : {toc - tic:0.4f} seconds\")\n",
    "print(\"#################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174018b5",
   "metadata": {},
   "source": [
    "## Convolutional autoencoder and DNN coupled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingFramework import TrainingFramework\n",
    "from TestingFramework import TestingFramework\n",
    "import Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc17832",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_network_sPOD = {\n",
    "        'time_amplitude_train': ta_train,\n",
    "        'time_amplitude_test': ta_test,\n",
    "        'parameter_train': PARAMS_TRAIN,\n",
    "        'parameter_test': PARAMS_TEST,\n",
    "        'batch_size': 100,\n",
    "        'num_early_stop': 500,  # Number of epochs for the early stopping\n",
    "        'pretrained_load': False,  # Wthere to initialize the network with pretrained weights\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'perform_svd': 'randomized',  # 'normal', 'randomized'\n",
    "        'learning_rate': 0.05,  # eta\n",
    "        'full_order_model_dimension': df.Nx,  # N_h\n",
    "        'reduced_order_model_dimension': df.D * df.NumFrames + df.NumFrames,  # N\n",
    "        'encoded_dimension': 4,  # dimension of the system after the encoder\n",
    "        'omega_h': 0.8,\n",
    "        'omega_N': 0.2,\n",
    "        'typeConv': '1D',  # Type of convolutional layer for the network : '1D' or '2D'\n",
    "        'totalModes': df.D * df.NumFrames,  # Total number of modes for all the frames\n",
    "        'NumOfFrames': df.NumFrames  # Total number of frames\n",
    "    }\n",
    "\n",
    "\n",
    "dict_network_POD = {\n",
    "        'time_amplitude_train': TA_POD_TRAIN,\n",
    "        'time_amplitude_test':TA_POD_TEST,\n",
    "        'parameter_train': PARAMS_TRAIN,\n",
    "        'parameter_test': PARAMS_TEST,\n",
    "        'batch_size': 100,\n",
    "        'num_early_stop': 10000,  # Number of epochs for the early stopping\n",
    "        'pretrained_load': False,  # Wthere to initialize the network with pretrained weights\n",
    "        'scaling': True,  # true if the data should be scaled\n",
    "        'perform_svd': 'randomized',  # 'normal', 'randomized'\n",
    "        'learning_rate': 0.05,  # eta\n",
    "        'full_order_model_dimension': df.Nx,  # N_h\n",
    "        'reduced_order_model_dimension': df.D * df.NumFrames,  # N\n",
    "        'encoded_dimension': 4,  # dimension of the system after the encoder\n",
    "        'omega_h': 0.8,\n",
    "        'omega_N': 0.2,\n",
    "        'typeConv': '1D',  # Type of convolutional layer for the network : '1D' or '2D'\n",
    "        'totalModes': df.D * df.NumFrames,  # Total number of modes for all the frames\n",
    "        'NumOfFrames': 0  # Total number of frames\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b705243",
   "metadata": {},
   "source": [
    "## -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cae56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the path to the pre trained weights\n",
    "PATH_sPOD = 'CADNN_result/synthetic/training_results_sPOD/2022_08_23__19-55-17/net_weights/epoch_99.pt'\n",
    "PATH_POD = 'CADNN_result/synthetic/training_results_sPOD/2022_08_23__19-55-17/net_weights/epoch_99.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model for sPOD\n",
    "train_model_sPOD = TrainingFramework(dict_network_sPOD, split=0.70, \n",
    "                                     log_folder='./CADNN_result/synthetic/training_results_sPOD/')\n",
    "trained_model_sPOD = train_model_sPOD.training(epochs=1000, save_every=50, print_every=50, \n",
    "                                               log_base_name='/', pretrained_weights=PATH_sPOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dda7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Testing model for sPOD\n",
    "testing_method = ''\n",
    "\n",
    "log_folder_base = 'CADNN_result/synthetic/training_results_sPOD/'\n",
    "log_folder_trained_model = sorted(pathlib.Path(log_folder_base).glob('*/'), key=os.path.getmtime)[-1]\n",
    "\n",
    "test_model_sPOD = TestingFramework(dict_network_sPOD)\n",
    "test_model_sPOD.testing(log_folder_trained_model=str(log_folder_trained_model), \n",
    "                        testing_method=testing_method, model=trained_model_sPOD)\n",
    "results_predicted_sPOD = test_model_sPOD.time_amplitude_test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d29c8",
   "metadata": {},
   "source": [
    "## -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8cc800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model for POD\n",
    "train_model_POD = TrainingFramework(dict_network_POD, split=0.70, \n",
    "                                    log_folder='./CADNN_result/synthetic/training_results_POD/')\n",
    "trained_model_POD = train_model_POD.training(epochs=1000, save_every=50, print_every=50, \n",
    "                                             log_base_name='/', pretrained_weights=PATH_POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Testing model for POD\n",
    "testing_method = ''\n",
    "\n",
    "log_folder_base = 'CADNN_result/synthetic/training_results_POD/'\n",
    "log_folder_trained_model = sorted(pathlib.Path(log_folder_base).glob('*/'), key=os.path.getmtime)[-1]\n",
    "\n",
    "test_model_POD = TestingFramework(dict_network_POD)\n",
    "test_model_POD.testing(log_folder_trained_model=str(log_folder_trained_model), \n",
    "                       testing_method=testing_method, model=trained_model_POD)\n",
    "results_predicted_POD = test_model_POD.time_amplitude_test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570cb89",
   "metadata": {},
   "source": [
    "## -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is reserved for data manipulations for the online analysis\n",
    "TA_sPOD_pred = results_predicted_sPOD[:-2, :]\n",
    "shifts_sPOD_pred = results_predicted_sPOD[-2:, :]\n",
    "TA_POD_pred = results_predicted_POD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f9d7b",
   "metadata": {},
   "source": [
    "## Online error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204744d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "errors = df.onlineErroranalysis(TA_sPOD_pred, shifts_sPOD_pred, TA_POD_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d78aaa1",
   "metadata": {},
   "source": [
    "# Error plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb116e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from Helper import save_fig\n",
    "from statistics import mean\n",
    "\n",
    "impath = \"../plots/images_synthetic/\"\n",
    "os.makedirs(impath, exist_ok=True) \n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Computer Modern\"]})\n",
    "\n",
    "SMALL_SIZE = 16   # 16\n",
    "MEDIUM_SIZE = 18   # 18\n",
    "BIGGER_SIZE = 20   # 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62eb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_modes = np.array([2, 4, 6, 8, 10, 12, 14, 16])\n",
    "E_sPOD = np.array([0.2698, 0.0798, 0.0264, 0.0102, 0.0049, 0.0031, 0.0022, 0.0007])\n",
    "E_POD = np.array([0.7878, 0.7079, 0.6376, 0.5739, 0.5159, 0.4596, 0.4052, 0.3595])\n",
    "E_sPOD_NN = np.array([0.384, 0.192, 0.122, 0.111, 0.0428, 0.0428, 0.0428, 0.0428])\n",
    "E_POD_NN = np.array([0.898, 0.868, 0.873, 0.824, 0.817, 0.817, 0.817, 0.817])\n",
    "E_sPOD_LI = np.array([0.382, 0.186, 0.116, 0.0813, 0.00286, 0.00286, 0.00286, 0.00286])\n",
    "\n",
    "err = errors[0]\n",
    "err_min = [min(x) for x in err]\n",
    "err_max = [max(x) for x in err]\n",
    "err_mean = [mean(x) for x in err]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axs[0].semilogy(truncated_modes, E_sPOD, color=\"black\", linestyle='-', marker=\".\", label=r\"$E_{\\mathrm{sPOD}}$\")\n",
    "axs[0].semilogy(truncated_modes, E_POD, color=\"red\", linestyle='-', marker=\".\", label=r\"$E_{\\mathrm{POD}}$\")\n",
    "axs[0].semilogy(truncated_modes, E_sPOD_NN, color=\"green\", linestyle='--', marker=\"*\", label=r\"$E^{\\mathrm{sPOD-NN}}_{\\mathrm{tot}}$\")\n",
    "axs[0].semilogy(truncated_modes, E_POD_NN, color=\"blue\", linestyle='--', marker=\"*\", label=r\"$E^{\\mathrm{POD-NN}}_{\\mathrm{tot}}$\")\n",
    "axs[0].semilogy(truncated_modes, E_sPOD_LI, color=\"yellow\", linestyle='--', marker=\"*\", label=r\"$E^{\\mathrm{sPOD-LI}}_{\\mathrm{tot}}$\")\n",
    "axs[0].set_xlabel('Number of modes')\n",
    "axs[0].set_ylabel('Errors')\n",
    "axs[0].grid()\n",
    "axs[0].legend(loc='lower left')\n",
    "\n",
    "axs[1].semilogy(df.t, err_min, color=\"green\", linestyle='--', label=r\"min$(E_{\\mathrm{t}})$\")\n",
    "axs[1].semilogy(df.t, err_max, color=\"black\", linestyle='--', label=r\"max$(E_{\\mathrm{t}})$\")\n",
    "axs[1].semilogy(df.t, err_mean, color=\"red\", linestyle='--', label=r\"mean$(E_{\\mathrm{t}})$\")\n",
    "axs[1].set_xlabel(r\"time $t$\")\n",
    "axs[1].grid()\n",
    "axs[1].legend(loc='lower right')\n",
    "\n",
    "\n",
    "save_fig(filepath=impath + 'Rel_err', figure=fig)\n",
    "fig.savefig(impath + \"Rel_err\" + \".eps\", format='eps',dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5d675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
